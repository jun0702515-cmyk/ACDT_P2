import { useState, useEffect, useRef } from 'react';
import './index.css'; 

function App() {
  // --- [ìƒíƒœ ê´€ë¦¬] ---
  const [isRunning, setIsRunning] = useState(false);
  const [statusText, setStatusText] = useState("System Standby");
  const [logs, setLogs] = useState([]);
  const [detectedStudents, setDetectedStudents] = useState({});
  const [showList, setShowList] = useState(false);

  // AI & ì„¼ì„œ ìƒíƒœ
  const [audioLabel, setAudioLabel] = useState("Standby");
  const [audioScore, setAudioScore] = useState(0);
  const [videoState, setVideoState] = useState("Closed");
  const [videoGap, setVideoGap] = useState(0);

  // --- [ì„¤ì •ê°’] ---
  const CONFIG = {
    confidence: 0.5,    // AI ì‹ ë¢°ë„ 50%
    mouthOpen: 0.004,   // ì…ë²Œë¦¼ ë¯¼ê°ë„ (4%)
    lipMovement: 0.002, // ì… ì›€ì§ì„ ë¯¼ê°ë„
    strictness: 3       // ì ë°œ ê¸°ì¤€ í”„ë ˆì„
  };

  // --- [ë‚´ë¶€ ë³€ìˆ˜] ---
  const videoRef = useRef(null);
  const canvasRef = useRef(null);
  const classifierRef = useRef(null);
  const audioCtxRef = useRef(null);
  const lipHistory = useRef([]);
  const violationQueue = useRef([]);
  const dbRef = useRef(null);
  const alertTimeout = useRef(null);

  // --- [ì´ˆê¸°í™”: íŒŒì´ì–´ë² ì´ìŠ¤] ---
  useEffect(() => {
    if (window.firebase && !dbRef.current) {
      const config = {
        apiKey: "AIzaSyDaLlrTKsMCpCzVgBW9icTmEPcuO_zoWVY",
        authDomain: "acdt-project.firebaseapp.com",
        projectId: "acdt-project",
        storageBucket: "acdt-project.firebasestorage.app",
        messagingSenderId: "243281762920",
        appId: "1:243281762920:web:6641d9eadfe1e93442f9dd",
        measurementId: "G-J9TVZXN3LE"
      };
      if (!window.firebase.apps.length) window.firebase.initializeApp(config);
      dbRef.current = window.firebase.firestore();
      
      // ëª…ë‹¨ ì‹¤ì‹œê°„ ë¡œë“œ
      dbRef.current.collection("detections").orderBy("timestamp", "desc")
        .onSnapshot(snap => {
          const st = {};
          snap.forEach(doc => {
            const d = doc.data();
            if (!st[d.studentId]) st[d.studentId] = { name: d.name, id: d.studentId, records: [] };
            st[d.studentId].records.push(d.timestamp ? new Date(d.timestamp.toDate()).toLocaleTimeString() : "-");
          });
          setDetectedStudents(st);
        });
    }
  }, []);

  // --- [í•µì‹¬ ë¡œì§: ì‹œì‘] ---
  const startSystem = async () => {
    const name = document.getElementById('inp-name').value;
    const id = document.getElementById('inp-id').value;
    if (!name || !id) { alert("Input Name & ID"); return; }

    setStatusText("Initializing...");
    try {
      // 1. AI ë¡œë“œ
      const cls = new window.EdgeImpulseClassifier();
      await cls.init();
      classifierRef.current = cls;

      // 2. ì˜¤ë””ì˜¤/ë¹„ë””ì˜¤ ì‹œì‘
      await startAudio();
      await startVideo();

      setIsRunning(true);
      setStatusText("Monitoring Active ğŸŸ¢");
    } catch (e) {
      alert("Error: " + e.message);
      window.location.reload();
    }
  };

  // --- [ë¡œì§: ì˜¤ë””ì˜¤] ---
  const startAudio = async () => {
    const AC = window.AudioContext || window.webkitAudioContext;
    const ctx = new AC();
    audioCtxRef.current = ctx;
    if (ctx.state === 'suspended') await ctx.resume();

    const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
    const src = ctx.createMediaStreamSource(stream);
    const proc = ctx.createScriptProcessor(4096, 1, 1);
    
    // ë²„í¼ ì²˜ë¦¬ (ì£¼íŒŒìˆ˜ ë³€í™˜)
    const targetRate = 16000;
    const bufferSize = 16000;
    let circBuffer = new Float32Array(bufferSize);
    let wIdx = 0;

    src.connect(proc);
    proc.connect(ctx.destination);

    proc.onaudioprocess = (e) => {
      if (!classifierRef.current) return;
      const input = e.inputBuffer.getChannelData(0);
      
      // ë‹¤ìš´ìƒ˜í”Œë§ (44.1kHz -> 16kHz)
      let rateRatio = ctx.sampleRate / targetRate;
      let newLen = Math.round(input.length / rateRatio);
      let res = new Float32Array(newLen);
      let offRes = 0, offBuf = 0;
      while (offRes < newLen) {
        let nextOff = Math.round((offRes + 1) * rateRatio);
        let accum = 0, count = 0;
        for (let i = offBuf; i < nextOff && i < input.length; i++) { accum += input[i]; count++; }
        res[offRes] = accum / count;
        offRes++; offBuf = nextOff;
      }

      for (let i = 0; i < res.length; i++) {
        circBuffer[wIdx] = res[i];
        wIdx = (wIdx + 1) % bufferSize;
      }

      // ë¶„ë¥˜ ì‹¤í–‰
      let linear = new Float32Array(bufferSize);
      for (let i = 0; i < bufferSize; i++) linear[i] = circBuffer[(wIdx + i) % bufferSize];

      try {
        let ret = classifierRef.current.classify(linear);
        let top = ret.results.reduce((p, c) => p.value > c.value ? p : c);
        setAudioLabel(top.label);
        setAudioScore(top.value);
      } catch (ex) {}
    };
  };

  // --- [ë¡œì§: ë¹„ë””ì˜¤] ---
  const startVideo = async () => {
    const vid = document.getElementById('hidden-video');
    const cvs = canvasRef.current;
    const ctx = cvs.getContext('2d');

    const faceMesh = new window.FaceMesh({ locateFile: (f) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${f}` });
    faceMesh.setOptions({ maxNumFaces: 1, refineLandmarks: true, minDetectionConfidence: 0.5 });

    faceMesh.onResults((res) => {
      cvs.width = 500; cvs.height = 500;
      ctx.fillStyle = "black"; ctx.fillRect(0, 0, 500, 500);

      let state = "Closed";
      
      if (res.image && res.multiFaceLandmarks.length > 0) {
        const lm = res.multiFaceLandmarks[0];
        const sW = vid.videoWidth; const sH = vid.videoHeight;
        const up = lm[13]; const low = lm[14];

        // ì¤Œ ê·¸ë¦¬ê¸°
        const zoom = 4.0; 
        const cw = sW/zoom; const ch = sH/zoom;
        let cx = ((up.x + low.x)/2 * sW) - cw/2;
        let cy = ((up.y + low.y)/2 * sH) - ch/2;
        ctx.drawImage(res.image, cx, cy, cw, ch, 0, 0, 500, 500);

        // ë¡œì§
        const gap = low.y - up.y;
        setVideoGap(Math.round((gap/0.05)*100));
        
        lipHistory.current.push(gap);
        if (lipHistory.current.length > 5) lipHistory.current.shift();
        
        // í‘œì¤€í¸ì°¨ ê³„ì‚°
        const mean = lipHistory.current.reduce((a,b)=>a+b,0)/lipHistory.current.length;
        const move = Math.sqrt(lipHistory.current.reduce((a,b)=>a+Math.pow(b-mean,2),0)/lipHistory.current.length);

        if (gap > CONFIG.mouthOpen) {
          state = move > CONFIG.lipMovement ? "Speaking" : "Open";
        }
        
        checkViolation(state);
      }
      setVideoState(state);
    });

    const camera = new window.Camera(vid, {
      onFrame: async () => { await faceMesh.send({ image: vid }); },
      width: 1280, height: 720
    });
    await camera.start();
  };

  // --- [íŒì • ë¡œì§] ---
  const checkViolation = (vState) => {
    // ì˜¤ë””ì˜¤ëŠ” Stateê°’ ì°¸ì¡° (React ë°©ì‹)
    // ì‹¤ì œë¡œëŠ” Refë¥¼ ì“°ëŠ”ê²Œ ë” ì •í™•í•˜ì§€ë§Œ, ê°„ë‹¨í•œ êµ¬í˜„ì„ ìœ„í•´ State ì‚¬ìš©
    const isKorean = audioLabel === 'korean' && audioScore > CONFIG.confidence;
    const isMouth = vState === "Speaking";

    if (isKorean && isMouth) violationQueue.current.push(1);
    else violationQueue.current.push(0);
    
    if (violationQueue.current.length > 10) violationQueue.current.shift();
    const cnt = violationQueue.current.filter(v => v === 1).length;

    if (cnt >= CONFIG.strictness) {
      doAlert();
    }
  };

  const doAlert = () => {
    if (alertTimeout.current) return;
    
    // UI ë³€ê²½
    const img = document.getElementById('monitor-img');
    const overlay = document.getElementById('overlay-alert');
    if (img) { img.src = "2.jpg"; img.classList.add('alert'); }
    if (overlay) overlay.style.display = 'block';

    // DB ì €ì¥
    const n = document.getElementById('inp-name').value;
    const i = document.getElementById('inp-id').value;
    if (dbRef.current) {
      dbRef.current.collection("detections").add({
        name: n, studentId: i, reason: "KOREAN", timestamp: window.firebase.firestore.FieldValue.serverTimestamp()
      });
    }

    // 3ì´ˆ í›„ ë¦¬ì…‹
    alertTimeout.current = setTimeout(() => {
      if (img) { img.src = "1.jpg"; img.classList.remove('alert'); }
      if (overlay) overlay.style.display = 'none';
      alertTimeout.current = null;
      violationQueue.current = [];
    }, 3000);
  };

  // --- [í™”ë©´ ê·¸ë¦¬ê¸°] ---
  return (
    <div className="app-container">
      {/* 1. ì‚¬ì´ë“œë°” */}
      <div id="sidebar">
        <div className="title"><h2>KOREAN KILLER</h2><div className="logo">KK</div></div>
        <input id="inp-name" type="text" placeholder="Name" />
        <input id="inp-id" type="text" placeholder="ID" />
        
        {!isRunning ? 
          <button className="btn-start" onClick={startSystem}>â–¶ Start</button> : 
          <button className="btn-stop" onClick={()=>window.location.reload()}>â¹ Stop</button>
        }
        
        <button className="btn-blue" onClick={() => setShowList(!showList)}>ğŸ“‹ List</button>
        <button className="btn-gray" onClick={() => {
           if(prompt("PW")==="kyj") { 
             document.getElementById('prof-area').style.display='block'; 
           }
        }}>ğŸ”’ Admin</button>

        <div id="prof-area" style={{display:'none', marginTop:'10px', borderTop:'1px solid #555', paddingTop:'10px'}}>
           <p style={{color:'orange', margin:0}}>Admin Mode</p>
           <button className="btn-red" onClick={async ()=>{
             if(confirm("DELETE ALL?")) {
               const s = await dbRef.current.collection("detections").get();
               const b = dbRef.current.batch();
               s.docs.forEach(d=>b.delete(d.ref));
               await b.commit();
             }
           }}>âš ï¸ Reset DB</button>
        </div>
      </div>

      {/* 2. ëª…ë‹¨ íŒ¨ë„ (ìˆ¨ê¹€/í‘œì‹œ) */}
      <div id="list-panel" className={showList ? 'open' : ''}>
        <h3>ğŸš¨ Detections</h3>
        <ul>
          {Object.values(detectedStudents).map(s => (
            <li key={s.id} className={s.records.length > 3 ? 'bad' : ''}>
              <b>{s.name}</b> ({s.id}) <span className="badge">{s.records.length}</span>
              <div className="times">{s.records.map((t,i)=><div key={i}>{t}</div>)}</div>
            </li>
          ))}
        </ul>
      </div>

      {/* 3. ë©”ì¸ í™”ë©´ */}
      <div id="main-content">
        {/* ì™¼ìª½: ì´ë¯¸ì§€ */}
        <img id="monitor-img" src="1.jpg" alt="Monitor" />

        {/* ì˜¤ë¥¸ìª½: ì¤Œ ì¹´ë©”ë¼ */}
        <div id="center-stage">
          {!isRunning && <div className="placeholder"><h1>Ready</h1><p>Enter info & Start</p></div>}
          
          <div id="cam-box" style={{display: isRunning ? 'block' : 'none'}}>
            <canvas ref={canvasRef} id="output_canvas"></canvas>
            <div id="overlay-alert">ğŸš¨ DETECTED!</div>
          </div>

          {/* ìƒíƒœ í‘œì‹œ (ì¤‘ì•™ í•˜ë‹¨) */}
          {isRunning && (
            <div className="status-bar">
              <span className={audioLabel === 'korean' && audioScore > CONFIG.confidence ? 'red' : ''}>
                ğŸ¤ {audioLabel.toUpperCase()} {Math.round(audioScore*100)}%
              </span>
              <span className={videoState === 'Speaking' ? 'green' : ''}>
                ğŸ‘„ {videoState} {videoGap}%
              </span>
            </div>
          )}
        </div>
      </div>

      {/* ìˆ¨ê²¨ì§„ ë¹„ë””ì˜¤ íƒœê·¸ */}
      <video id="hidden-video" ref={videoRef} playsInline autoPlay style={{display:'none'}}></video>
    </div>
  );
}

export default App;
